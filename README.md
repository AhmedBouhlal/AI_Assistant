## ğŸ§  Modular AI Assistant

A smart, modular, GUI-based Python assistant built for automation, file management, and local AI interactions. Fully customizable and extensible via plug-and-play skills.

---

## âœ¨ Features

- ğŸ§© Modular skills system â€” drop-in Python files to add new abilities
- ğŸ“ File system tools (search, disk usage, cleanup)
- ğŸ“Š System monitoring utilities
- ğŸ“¦ Simple, pop-up GUI interface (no browser needed)
- ğŸ“œ Easy skill logging and auditing
- ğŸ› ï¸ Works offline â€” no ChatGPT, DeepSeek, or external APIs required

---

## ğŸ—‚ï¸ Folder Structure

.
â”œâ”€â”€ assistant_main.py # Entry point for the GUI assistant

â”œâ”€â”€ assistant_core.py # Loads and executes skills

â”œâ”€â”€ ai_interface.py # Connects to local models like LLaMA (via Ollama)

â”œâ”€â”€ assistant_config.py # Stores model/host configurations

â”œâ”€â”€ skills/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ file_search.py
â”‚ â”œâ”€â”€ disk_usage.py
â”‚ â”œâ”€â”€ your_custom_skills.py
â”‚ â””â”€â”€ ...

## ğŸ› ï¸ How It Works

1. **Each skill** is a Python file in the `skills/` folder.
2. Each file must include a `register()` function returning:
   - Skill name
   - Function to call
   - Description
   - (Optional) Access level

```python
def register():
    return {
        "name": "file_search",
        "function": search_files,
        "description": "Searches for files on your system.",
        "security": "open"
    }
3. Skills are auto-loaded and callable from the GUI or CLI.

##ğŸš€ Getting Started

1. Install dependencies:

```bash
pip install -r requirements.txt

2. Run the assistant:

```bash
python main_gui.py

##ğŸ§  How to Add a New Skill

1. Create a new Python file inside skills/, e.g. hello.py
2. Write your function and register it:

```python
def hello_world():
    return "Hello, user!"

def register():
    return {
        "name": "hello",
        "function": hello_world,
        "description": "Says hello.",
        "security": "open"
    }
3. It will automatically load on next run.

.

##ğŸ›¡ï¸ Security

You can tag any skill as "open" or "restricted" to control access.

##ğŸ¤– Model Integration

Uses a local Ollama instance running a model like LLaMA 3. You can configure it via:

assistant_config.py
```python
OLLAMA_MODEL = "llama3"
OLLAMA_HOST = "http://localhost:11434/api/generate"

##ğŸ“ Logs

All skill calls are logged via log_action(skill_name, data) in assistant_core.py.

##ğŸ“Œ Notes

The assistant runs fully offline.
You are free to add or remove any skills in skills/

##ğŸ§  License

MIT â€” free to use, modify, and redistribute.

##ğŸ™Œ Credits

Built by [Ahmed BOUHLAL] for productivity, automation, and AI experimentation.
